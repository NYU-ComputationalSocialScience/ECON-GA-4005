{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148ae52b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- Linear Algebra\n",
    "- Linear Models\n",
    "- Overfitting and Model Selection\n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand the concept of regularization\n",
    "- Be familiar with common forms of regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11da3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Review: Overfitting, Model Selection, Validation Procedures\n",
    "\n",
    "- **Goal** of supervised learning is to maximize *out of sample* performance\n",
    "- We fit a model (or many models) on training data and examine *metrics* or *losses*\n",
    "- If we optimize for minimal loss on training data we risk **overfitting**\n",
    "- When we overfit, model performs **significantly** better on training data than out of sample data\n",
    "- This hurts our goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b31e4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Hold Out Sets\n",
    "\n",
    "- To minimize risk of overfitting, we hold back some data from training set\n",
    "- We call this data either **validation** data or **test** data, depending on how it is used\n",
    "    - Either way it is called **hold-out** data\n",
    "- After training, we evaluate metrics on hold out data (gives estimate of out of sample performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be90fef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Model Selection and Validation Procedures\n",
    "\n",
    "- To increase chances of finding a model that meets our goal, we will train many models\n",
    "- These models may vary in structure, distributional assumptions, or family \n",
    "- We use a **validation procedure** like the hold-out method or k-fold CV to select the champion model from our set of models\n",
    "- Main intution behind a validation procedure is:\n",
    "    1. Accurately estimate out of sample performance for all models\n",
    "    2. Select model with lowest out hold-out set metric score as chamption model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577dbdef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Types of Candidate Pools\n",
    "\n",
    "-   The validation procedures begin with defining a set of candidate models\n",
    "-   We call this the **candidate pool**\n",
    "-   Common types of candidate pools are:\n",
    "    -   Models of the same structure that consider different sets of features (here validation helps in **feature selection**)\n",
    "    -   Family of models indexed by one or more hyper parameters (e.g. structure of neural network -- here validation addresses **model regularization**)\n",
    "    -   A potpourri collection of models not belonging to a common family -- called a **bag of models**, for lack of a better term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3b6ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Regularization\n",
    "\n",
    "-   **Model regularization** is an approach to *avoid overfitting*\n",
    "    in models that are *over-parameterized*\n",
    "-   In ML, regularization started as a heuristic approach to avoid overfitting, but later on theory was developed that justified its use\n",
    "-   We will (mostly) approach regularization as a heuristic, but the theoretical side is fascinating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad9c0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Motivation\n",
    "\n",
    "-   Suppose we have an over-parameterized linear regression model\n",
    "-   In this case we know that the number of parameters $P$ is greater than or equal to the number of training samples $N$\n",
    "-   We also know that overfitting is guaranteed to occur (training MSE will be 0)\n",
    "-   How can we we prevent overfitting from occurring?\n",
    "-   **Idea**: Prevent the model parameters from taking values that minimize (zero-out) the training MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5675f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "... But how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d7eb0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Penalizing the Loss Function\n",
    "\n",
    "-   Instead of minimizing the training MSE, minimize the sum of the training MSE plus a penalty (a.k.a. regularization) term\n",
    "\n",
    "$$\\min_{\\theta \\in \\mathbb{R}^P} \\bigg[\\frac{1}{N} \\sum_{n=1}^N \\ell(y_n, f(x_n | \\theta) ) + {\\color{green} \\mu} {\\color{red}R(\\theta)} \\bigg], \\quad \\mu \\ge 0$$\n",
    "\n",
    "-   Notice the non-negative <span style=\"color: green\">regularization parameter $\\mu$</span>\n",
    "-   Also the non-negative  <span style=\"color: red\">regularization term $R(\\theta)$</span>\n",
    "    -   $R$ satisfies $\\frac{\\partial d}{\\partial \\theta} > 0$\n",
    "    -   Typically, $R( \\cdot )$ is a function of one of $\\theta$'s norms, i.e. it is really $R(\\| \\theta \\|)$. We will make this assumption\n",
    "    -   Typically $R(0)=0$\n",
    "\n",
    "-   We will refer to the whole expression as **regularized (average)\n",
    "    loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a54b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Summary\n",
    "\n",
    "- We can minimize the penalized loss\n",
    "$$\\min_{\\theta \\in \\mathbb{R}^P} \\bigg[\\frac{1}{N} \\sum_{n=1}^N \\ell(y_n, f(x_n | \\theta)) + \\mu R(\\theta) \\bigg], \\quad \\mu \\ge 0$$\n",
    "- This is one of the classic ways to apply regularization\n",
    "- This type of regularization is called **Tikhonov regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f4357",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Effect of Regularization Parameter ($\\mu$)\n",
    "\n",
    "- A quick definition:\n",
    "$$\\theta_{\\mu}^* \\triangleq \\argmin_{\\theta \\in \\mathbb{R}^P} \\bigg[\\frac{1}{N} \\sum_{n=1}^N \\ell(y_n, f(x_n | \\theta)) + \\mu R(\\theta)\\bigg], \\quad \\mu \\ge 0$$\n",
    "- Notice that, if $\\mu=0$, we get the weight vector that minimizes the non-regularized training MSE, i.e. $\\theta_0^* = \\theta^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0249fdf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Increasing $\\mu$\n",
    "\n",
    "-   If we scale a function by multiplying it by a positive constant, its minimizer(s) remain the same\n",
    "We can divide the regularized loss by $\\mu > 0$ to obtain:\n",
    "$$\\begin{aligned}\n",
    "\\argmin_{\\theta \\in \\mathbb{R}^P} \\bigg[ \\frac{1}{N \\mu} \\sum_{n=1}^N \\ell(y_n, f(x_n|\\theta)) + R\\big( \\| \\theta \\| \\big ) \\bigg] = \\theta_{\\mu}^*\n",
    "\\end{aligned}$$\n",
    "- Now consider increasing $\\mu$ towards $\\infty$:\n",
    "$$\\begin{aligned}\n",
    "\\theta_{\\infty}^* & \\triangleq \\lim_{\\mu \\to +\\infty} \\argmin_{\\theta \\in \\mathbb{R}^P} \\bigg[ \\frac{1}{N \\mu} \\sum_{n=1}^N \\ell(y_n, f(x_n|\\theta)) + R\\big( \\| \\theta \\| \\big ) \\bigg]\\\\\n",
    "& = \\arg \\min_{\\theta \\in \\mathbb{R}^P} R\\big( \\| \\theta \\| \\big )\\\\\n",
    "&= 0\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceccf826",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### $\\mu$ vs $\\theta_{\\mu}^*$\n",
    "\n",
    "\n",
    "![Regularization Parameter](https://css-materials.s3.amazonaws.com/ML/regularization/regularization_parameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a81b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Question -- what is $\\mu$?\n",
    "\n",
    "**What is $\\mu$?**\n",
    "\n",
    "1.  A model parameter\n",
    "2.  A hyperparameter\n",
    "3.  Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544f5f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### How to choose the best $\\mu$?\n",
    "-   By a validation procedure, of course!\n",
    "    -   Q: What is the optimal value of $\\mu$ that minimizes the\n",
    "        regularized loss, and depends only on the training data?\n",
    "    -   A: trick question -- we can't determine it from the training data!\n",
    "-   $\\mu$ is a hyperparameter\n",
    "-   It is as if for each $\\mu$ we have a different model, for which the optimal weights are $\\theta_{\\mu}^*$\n",
    "-   Hence, $\\mu$ indexes a family of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fafcf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### An Equivalent View\n",
    "\n",
    "- Under some relatively mild regularity conditions, one can show that $\\forall \\mu, \\exists r \\ge 0$ such that\n",
    "$$\\begin{aligned}\n",
    "&\\min_{\\theta \\in \\mathbb{R}^P} \\bigg[\\frac{1}{N} \\sum_{n=1}^N \\ell(y_n, f(x_n | \\theta)) + \\mu R(\\theta)\\bigg] \\\\\n",
    "= &\\min_{\\theta \\in \\mathbb{R}^P: \\| \\theta \\| \\leq r} \\frac{1}{N} \\sum_{n=1}^N \\ell(y_n, f(\\mathbf{x}_n|\\theta))\n",
    "\\end{aligned}$$\n",
    "- The latter expression is called **Ivanov regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4375b67",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Ivanov vs. Tikhonov\n",
    "\n",
    "![Ivanov Vs Tikhonov](https://css-materials.s3.amazonaws.com/ML/regularization/ivanov_vs_tikhonov.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b96f46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Common Choices of Regularizers $R(\\cdot)$\n",
    "\n",
    "- Squared Euclidean (L2) norm: $$R(\\|\\theta\\|) = \\|\\theta\\|_2^2 = \\theta^T\\theta$$\n",
    "    - Differentiable (has gradient vector everywhere) 😊\n",
    "    - Mathematically convenient(For linear regression we know the regularized solution in closed form) 😊\n",
    "    - Does not promote parameter sparsity (will explain) 🙁"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84279a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "- $L_1$ norm: $$R(\\|\\theta\\|) = \\|\\theta\\|_1 = \\sum_{p=1}^P | w_p |$$\n",
    "    - Non-differentiable (no gradient at some points) $\\Longrightarrow$ no closed-form solutions $\\Longrightarrow$ necessitates more sophisticated algorithms to work with 🙁\n",
    "    - Promotes **sparsity** 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abee05",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Parameter Sparsity\n",
    "\n",
    "\n",
    "![l1 vs l2 regulariztion](https://css-materials.s3.amazonaws.com/ML/regularization/l1_vs_l2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4aa875",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Other Forms of Regularization\n",
    "\n",
    "-   Some more exotic approaches (won't show why it works, though)\n",
    "    -   **Data augmentation** Create new artificial training samples by randomly picking among the original ones and adding some noise to them (commonly used for image data)\n",
    "    -   **Drop-out**: Randomly set some parameters to zero on each iteration during training (dropout is pretty much standard practice in modern deep learning)\n",
    "-   Both of the above can be shown to be equivalent to special types of regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9b479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31582b9feba862c420bc95ad7fac43fb721c474490d1710b4e50ac63470f9531"
  },
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
